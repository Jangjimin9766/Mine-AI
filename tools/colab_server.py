# =================================================================
# Mine-AI: Google Colab GPU Image Server (SDXL)
# =================================================================
# ì´ ì½”ë“œë¥¼ Google Colabì˜ ìƒˆ ë…¸íŠ¸ë¶ ì…€ì— ë¶™ì—¬ë„£ê³  ì‹¤í–‰í•˜ì„¸ìš”.
# ì‹¤í–‰ ì „: [ëŸ°íƒ€ì„] -> [ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½] -> [T4 GPU] ì„ íƒ í™•ì¸

# 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
!pip install -q fastapi uvicorn pyngrok pydantic diffusers transformers accelerator safetensors

import torch
from diffusers import DiffusionPipeline
from fastapi import FastAPI
from pydantic import BaseModel
import base64
from io import BytesIO
import uvicorn
from pyngrok import ngrok
import nest_asyncio

# 2. Stable Diffusion XL ëª¨ë¸ ë¡œë“œ
print("â³ Loading SDXL Model (this takes a few minutes)...")
pipe = DiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0",
    torch_dtype=torch.float16,
    use_safetensors=True,
    variant="fp16"
)
pipe.to("cuda")
print("âœ… Model Loaded on GPU!")

# 3. FastAPI ì„œë²„ ì„¤ì •
app = FastAPI()

class GenerateRequest(BaseModel):
    prompt: str

@app.post("/generate")
async def generate(req: GenerateRequest):
    print(f"ğŸ¨ Generating image for: {req.prompt[:50]}...")
    image = pipe(prompt=req.prompt, num_inference_steps=30).images[0]
    
    buffered = BytesIO()
    image.save(buffered, format="PNG")
    img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
    
    return {"image_url": f"data:image/png;base64,{img_str}"}

# 4. Ngrok í„°ë„ë§ ë° ì‹¤í–‰
# ì‚¬ìš©ìê°€ ì œê³µí•œ í† í°ìœ¼ë¡œ ì¸ì¦ ì„¤ì •
!ngrok config add-authtoken 38jPwLfZkU7IwoZXw3RUz86Lmze_6cY6R4yhWrYhb9iEvhJTZ

import threading

def run_server():
    print("\nğŸš€ Starting FastAPI server on port 8000...")
    config = uvicorn.Config(app, host="0.0.0.0", port=8000, log_level="info")
    server = uvicorn.Server(config)
    # Colabì˜ ì´ë²¤íŠ¸ ë£¨í”„ì™€ ì¶©ëŒí•˜ì§€ ì•Šë„ë¡ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
    server.run()

# ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì„œë²„ ì‹œì‘
server_thread = threading.Thread(target=run_server)
server_thread.start()

print("\nğŸš€ Starting Public Tunnel...")
public_url = ngrok.connect(8000).public_url
print(f"\n====================================================")
print(f"ğŸ”— COPY THIS URL: {public_url}/generate")
print(f"====================================================\n")
print("ìœ„ URLì„ Mine-AIì˜ .env íŒŒì¼ REMOTE_IMAGE_SERVER_URLì— ë„£ìœ¼ì„¸ìš”.")
print("ì„œë²„ê°€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. (ì˜¤ë¥˜ ë©”ì‹œì§€ê°€ ëœ¨ë”ë¼ë„ ìœ„ URLì´ ë‚˜ì˜¤ë©´ ì„±ê³µì…ë‹ˆë‹¤)")